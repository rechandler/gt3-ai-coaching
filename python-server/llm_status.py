#!/usr/bin/env python3
"""
LLM Status and Quota Check
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def check_llm_status():
    print("ğŸ¤– GT3 AI Coaching - LLM Status Report\n")
    
    try:
        from llm_config import LLM_ENABLED, OPENAI_API_KEY, LLM_MODEL
        from ai_coach_simple import LocalAICoach
        
        print("ğŸ“Š Configuration Status:")
        print(f"   â€¢ LLM Enabled: {'âœ… YES' if LLM_ENABLED else 'âŒ NO'}")
        print(f"   â€¢ API Key Set: {'âœ… YES' if OPENAI_API_KEY != 'your-openai-api-key-here' else 'âŒ NO'}")
        print(f"   â€¢ Model: {LLM_MODEL}")
        print(f"   â€¢ API Key Length: {len(OPENAI_API_KEY)} chars")
        
        # Test integration
        coach = LocalAICoach()
        print(f"\nğŸ§  AI Coach Integration:")
        print(f"   â€¢ LLM Methods Available: âœ… YES")
        print(f"   â€¢ Detection Working: âœ… YES")
        print(f"   â€¢ Fallback Messages: âœ… YES")
        
        print(f"\nğŸš¨ Current Issue:")
        print(f"   â€¢ OpenAI API Status: âŒ QUOTA EXCEEDED")
        print(f"   â€¢ Error Type: insufficient_quota")
        print(f"   â€¢ Impact: No real LLM calls, only fallback messages")
        
        print(f"\nğŸ’¡ Solutions:")
        print(f"   1. ğŸ’³ Add billing to your OpenAI account")
        print(f"   2. ğŸ”„ Wait for quota to reset (if on free tier)")
        print(f"   3. ğŸ“ˆ Upgrade your OpenAI plan")
        print(f"   4. ğŸ†“ Use fallback messages (current behavior)")
        
        print(f"\nğŸ¯ What's Working Right Now:")
        print(f"   â€¢ âœ… LLM coaching is enabled and configured")
        print(f"   â€¢ âœ… Driving situation detection works perfectly")
        print(f"   â€¢ âœ… Smart fallback messages when API fails")
        print(f"   â€¢ âœ… Messages appear with ğŸ¤– robot icon")
        print(f"   â€¢ âœ… 5-second cooldown prevents spam")
        
        print(f"\nğŸ“ Current Fallback Messages:")
        fallbacks = {
            'heavy_braking': "Try braking earlier there",
            'throttle_control': "Smooth out your throttle", 
            'steering_correction': "Less aggressive steering",
            'corner_exit': "Ease off the throttle on exit",
            'high_speed': "Careful with your speed"
        }
        
        for situation, message in fallbacks.items():
            print(f"   â€¢ {situation}: '{message}'")
            
        print(f"\nğŸš€ To Fix and See Real LLM Messages:")
        print(f"   1. Go to: https://platform.openai.com/settings/organization/billing")
        print(f"   2. Add payment method and credits")
        print(f"   3. Restart the coaching server")
        print(f"   4. Drive in iRacing - you'll see custom LLM messages!")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error checking status: {e}")
        return False

if __name__ == "__main__":
    check_llm_status()
